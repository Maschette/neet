% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Coding to code::proof: Practice fundamentals of automated testing for collaborative data analysis development},
  pdfauthor={sketch-draft by lead author, Charles T. Gray},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{cslreferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}

\title{Coding to \texttt{code::proof}: Practice fundamentals of
automated testing for collaborative data analysis development}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{How to go from no tests, to \emph{whoa} tests!}
\author{sketch-draft by lead author, Charles T. Gray}
\date{}

\begin{document}
\maketitle

\hypertarget{version-of-this-manuscript}{%
\subsection{Version of this
manuscript}\label{version-of-this-manuscript}}

This manuscript will go through three phases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A lead author sketch draft.
\item
  Implementation with the reproducibiliity team for
  \href{https://replicats.research.unimelb.edu.au/}{The repliCATS
  Project} \& version listing any team members who wish to co-author.
\item
  Implementation of repliCATS procedures, explicitly, after we need not
  blind the algorithms for experimental ingegrity. Invitation for
  external co-authors to contribute and extend the content, review, and
  final submission. Possibly for useR2020.
\end{enumerate}

\hypertarget{coding-to-doneness}{%
\section{Coding to doneness}\label{coding-to-doneness}}

Contrapunctus I is rarely learnt in one sitting. Indeed, for most
pianists, to even play the piece is the result of many months' diligent
work, and still it will never feel \emph{done}. For the student of the
opening work of Bach's \emph{The Art of Fugue}, the spent time at the
keyboard in order to play through a three-minute piece of music can seem
immeasurable. To play well, a diligent pianist must employ technqiue.
But \emph{how} a pianist is to achieve the desired technique is not
clear (Chang 2009).

For a researcher performing an analysis using a computational tool such
as R, it can be unclear when an analysis is \emph{done}. And, while
there are technical guides on \emph{good enough} practice, it can feel
overwhelming as to what to adopt and where. Particularly for an
in-development algorithm, which is to say, an algorithm with scripts
already started, and some results explored.

This manuscript picks up from where Riederer left off with
\emph{RMarkdown-driven development} and suggests a \emph{coderegistering
test-driven workflow} for coding to doneness. This workflow provides a
roadmap to completion for a packaged analysis with
\texttt{code::proof}ed the manuscript {[}(Gray 2019){]}, provided
measures of confidence in the implementaiton of the algorithm.

Musicians and, similarly, athletes, do not see themselves as having
mastered a skill, but active practitioners of a craft (Galway 1990). To
be a flautist is to practice, and to be athlete is to train. For
researcher developers, it can be hard to assess when an analysis is
completed. In this manuscript, we consider the \emph{practice} of
test-driven analysis development as a means of \emph{coding to doneness}
for an algorithm, a workflow that faciliates the analyst achieving a
sufficience sense of \texttt{code::proof} in their algorithm, confidence
in the implementation of the aglorithm (Gray 2019).

\hypertarget{questionable-research-practices-in-scientific-computing}{%
\section{Questionable research practices in scientific
computing}\label{questionable-research-practices-in-scientific-computing}}

Algorithms are coded by people who practice code, and significant
problems emerge when algorithms are treated as fixed artifacts, rather
than one of the tools utilised by those who \emph{practice} code. In
Australia, a heartbreakingly-ongoing example of this kind of problem
with the income-reporting data analyis algorithm that assesses if income
welfare recipients have been overpaid entitlements. Crude averaging
calculations have lead to ongoing incorrect debt notices issued, such as
20,000 people receiving ``robodebt'' notices for debts they did not owe
(McIlroy 2017). Problems in data analysis have real impacts on real
people's lives. Perhaps, if the algorithm were considered a workflow
practiced and monitored by a team of data scientists, rather than a
static object, problems would not be persisting to this day (Karp 2019).
Indeed, as noted in Wilson's testing primers (in development) for
\href{https://rstudio.cloud/learn/primers}{RStudio} (``RStudio Cloud,''
n.d.),

\begin{quote}
Almost all (92\%) of the catastrophic system failures are the result of
incorrect handling of non-fatal errors explicitly signaled in software.
In 58\% of the catastrophic failures, the underlying faults could easily
have been detected through simple testing of error handling code (Yuan
et al. 2014).
\end{quote}

We might view this as a computational instantiation of what Fraser
\emph{et al.} denote \emph{questionable research practices} (QRPs). The
QRPs Fraser \emph{et al.} provide a taxonomy for refer to various
practices in scientific methodology found in ecology and evolution, such
as \(p\)-hacking, adjusting a model's specification to achieve a desired
\(p\)-value, or \emph{cherry picking}, failing to report variables or
results that do not fit a desired narrative. QRPs are, importantly,
often not a result of scientific malpractice, but a question of
discipline-specific conventions established in bygone eras not
translating well to data-driven research (Fraser et al. 2018). In
scientific computing, as the robodebt example illustrates, similar and
overlapping errors may occur.

A consideration when providing recommendations of best practice is what
me might reasonably expect of a researcher. Indeed, it is likely
unrealistic to expect \emph{best practices} in scientific computing
(Wilson et al. 2014), perhaps we would be better off asking for
\emph{good enough} practices (Wilson et al. 2017) in scientific
computing. For while researchers use computational algorithms in science
every day, most of them are not trained in computational science. Even
mathematicians and statisticians do a great deal of training at the
blackboard, rather than the computer.

Riederer identifies several qrps in scientific computing, for example,
hardcoded values that interfere with another's ability to reproduce the
computational results (Riederer 2019). As researcher software engineers,
it behoves us to consider what are questionable research practices in
software produced for data analyses. Version control and open code
sharing via a platform such as GitHub, is one way to mitigate
questionable research practices in scientific computing (Bryan 2017).
There is also a growing literature on reproducible research compendia
via packaged analyses (Marwick, Boettiger, and Mullen 2018; Wilson et
al. 2017).

This manuscript contributes to this literature by focussing on workflows
for using automated tests to move analysis a fully reproducible packaged
research compendium. Furthermore, these workflosw assist the developer
communicate what they have coded to others and their future self, as a
means of mitigating questionable research practices in scientific
computing. Above all, by providing a workflow for the \emph{practice} of
code, the developer anxiety is reduced by having the parameters as
clearly defined as they can be from the start.

\hypertarget{practice-fundamentals}{%
\section{Practice fundamentals}\label{practice-fundamentals}}

Chuang C. Chang's \emph{Fundamentals of Piano Practice} sets out to
address a gap in piano pedagogy (Chang 2009). A similar gap exists in
the implementation of \emph{good enough} practices (Wilson et al. 2017),
which is to say, what we might reasonably expect of a analyst, in
reproducible computing for research data analyses. The objective is
different from advanced pianism, but we characterise testing
\emph{practice}, as opposed to \emph{techique}, analogous to how Change
delineates between \emph{piano} practice and technique. Through
attempting to identify the fundamentals of automated testing for
collaborative data analysis development, this manuscript aims to
articulate the gap in understanding automated testing implementation for
analysts.

As Chang notes, whilst there a rich history of technical pedagogy, there
is a dearth of guidance for pianists on \emph{learning} the technique
(Chang 2009). There are many canonical texts of pianistic technique
pedagogy. Bach provides a pathway from small canons {[}todo: cite{]}, to
two-part inventions{[}todo: cite{]}, three-part sinfonia, and the
challenge of \emph{The Well-Tempered Clavier} and \emph{The Art of
Fugue}. Bartok provides the \emph{Mikrokosmos} {[}todo: {]}, and
Czerny's \emph{School of Velocity} {[}to do{]}. In each case, technical
exercises of increasing difficulty are provided. In piano pedagogy, a
\emph{technical} exercise isolates a particular aspect of pianistic
technique {[}todo examples{]}. For example, {[}todo Czerny staccato{]}.
Or, {[}todo voicing technique{]}.

The dearth that Chang attempts to address is in pianistic
\emph{practice} habits that will lead to succesful adoption of these
techniques. In science, we might call this \emph{work flow} {[}todo
cite{]}.

\begin{quote}
.. practically every piano learning method consists of showing students
what to practice, and what kinds of techniques (runs, arpeggios, legato,
staccato, trills, etc.) are needed. There are few instructions on how to
practice order to be able to play them, which is mostly left to the
student and endless repetitions (Chang 2009).
\end{quote}

Wilson et al.~followed their work on \emph{best practices} in scientific
computing (Wilson et al. 2014), with a reflection on \emph{good enough}
practices (Wilson et al. 2017), in recognition that we must account for
what we might reasonably request of practitioners of data analysis. In
this manuscript, we consider one component of \emph{good enough}
practice in data analysis: \emph{automated testing}.

Automated tests are a formalised way of implementing checks that inputs
and outputs of algorithsms are as expected (Wickham 2015). Informative
messages are output that assist the developer in identifying where code
is not performing as expected.

\hypertarget{collaboration-via-automated-testing}{%
\section{Collaboration via automated
testing}\label{collaboration-via-automated-testing}}

At heart, automated tests are collaborative. This may be with others,
but applies at least as much to a analyst approaching their own past
work with which they have become unfamiliar, or have become anxious
about some aspect of the work. Automated tests provide an efficient way
of returning to and extending an analysis; anxiety is reduced by having
defined outcomes to code explicitly for.

Reproducible research compendia provide a means by which analysts can
share their work so that it may be extended by others, and automated
tests provide \texttt{code::proof} (Gray 2019), a measure of confidence
in the algorithm for others. Hayes expresses concern about using
algorithms published without automated tests (Hayes 2019). However, only
one quarter of the largest repository of R packages,
\href{https://cran.r-project.org/}{The Comprehensive R Archive Network},
have any automated tests (Hester 2016), highlighting that, despite
testing identified as a `vital' part of data analysis (Wickham 2015),
automated testing is yet to be widely adopted.

\hypertarget{a-test-driven-toolchain-walkthrough-for-in-development-analyses}{%
\section{A test-driven toolchain walkthrough for in-development
analyses}\label{a-test-driven-toolchain-walkthrough-for-in-development-analyses}}

In this section we now consider the practicality of implementing tests
through a \emph{toolchain walkthrough}, an opinionated documetation of a
scientific workflow , towards a measure of \texttt{code::proof},
confidence in the algorithm implemented (Gray 2019). In particular, a
toolchain walkthrough is a reflection of \emph{one} workflow, whilst
others, indeed, better, workflows might exist. This is in contrast to a
comprehensive review of tools. Instead, a toolchain walkthrough
ruminates on considerations \emph{after} a set of tools have been
chosen.

Toolchain walkthroughs aim to identify obstacles and advantages in
implementation of scientific workflows. By necessity, a toolchain
walkthrough is language specific, but, ideally, observations emerge that
are useful for any appropriate language employed for data analysis, such
as Python. This toolchain walkthrough examines the \emph{process},
analogous to piano \emph{practice}, of implementing tests, as opposed to
defining comprehensively the nature of \emph{good enough} tests,
analogous to guidance on pianistic technique.

\hypertarget{objective-of-this-toolchain-walkthrough}{%
\subsection{Objective of this toolchain
walkthrough}\label{objective-of-this-toolchain-walkthrough}}

This toolchain walkthrough aims to provide guidance on implementing a
test-driven workflow for an in-development analysis. Many analyses begin
as scripts that develop {[}todo expan{]} (Riederer 2019). The central
question of this manuscript is what constitutes a minimal level of
testing for in-development analysis, where code is still being written
and features implemented. Automated tests assist in time-consuming
debugging tasks (Wickham 2015), but also in providing information with a
developer who is unfamiliar with the code.

This is a first effort in identifying the fundamentals of automated
testing for the collaborative process of developing an analysis in R.
Analgous to Riederer's \emph{RMarkdown-driven development} (Riederer
2019), which deconstructs the workflow of developing an analysis from
.Rmd notebook-style reports to packaged analyses, we consider a set a
computational tools that form a workflow to assist in the coherent
development of automated tests for data analysis. This is an extension
of the workflow suggestions provided in \emph{R Packages}, with a
specific focus on collaborative workflows in research.

\hypertarget{devops-and-assumed-expertise}{%
\subsection{Devops and assumed
expertise}\label{devops-and-assumed-expertise}}

This toolchain walkthrough assumes a knowledge of R advanced enough to
be using the language to be answering scientific research claims.

\begin{itemize}
\tightlist
\item
  tools used: testthat, neet, covr
\item
  GitHub
\end{itemize}

\hypertarget{case-study}{%
\subsection{Case study}\label{case-study}}

\hypertarget{varameta}{%
\subsubsection{\texorpdfstring{\texttt{varameta::}}{varameta::}}\label{varameta}}

The \texttt{varameta::} package is in-development analysis support
software for a forthcoming manuscript, Meta-analysis of Medians.

\hypertarget{get-an-overview-with-covr}{%
\subsection{\texorpdfstring{Get an overview with
\texttt{covr::}}{Get an overview with covr::}}\label{get-an-overview-with-covr}}

With a packaged analysis, it's easy to get a sense of existing automated
testing coverage, if any tests have been written. The analysis functions
provided by \texttt{varameta::} were put on hold while signficant
discussion was written.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(covr)}
\KeywordTok{package\_coverage}\NormalTok{(}\StringTok{"\textasciitilde{}/Documents/repos/varameta/"}\NormalTok{)}
\CommentTok{\#> varameta Coverage: 70.71\%}
\CommentTok{\#> R/dist\_name.R: 0.00\%}
\CommentTok{\#> R/g\_cauchy.R: 44.44\%}
\CommentTok{\#> R/g\_norm.R: 71.43\%}
\CommentTok{\#> R/hozo\_se.R: 92.31\%}
\CommentTok{\#> R/bland\_mean.R: 100.00\%}
\CommentTok{\#> R/bland\_se.R: 100.00\%}
\CommentTok{\#> R/effect\_se.R: 100.00\%}
\CommentTok{\#> R/g\_exp.R: 100.00\%}
\CommentTok{\#> R/g\_lnorm.R: 100.00\%}
\CommentTok{\#> R/hozo\_mean.R: 100.00\%}
\CommentTok{\#> R/wan\_mean\_C1.R: 100.00\%}
\CommentTok{\#> R/wan\_mean\_C2.R: 100.00\%}
\CommentTok{\#> R/wan\_mean\_C3.R: 100.00\%}
\CommentTok{\#> R/wan\_se\_C1.R: 100.00\%}
\CommentTok{\#> R/wan\_se\_C2.R: 100.00\%}
\CommentTok{\#> R/wan\_se\_C3.R: 100.00\%}
\end{Highlighting}
\end{Shaded}

Created on 2020-02-01 by the \href{https://reprex.tidyverse.org}{reprex
package} (v0.3.0)

The \texttt{covr::} function \texttt{package\_coverage} provides the
percentage of the lines of code run in tests and is a succinct method to
get an at-a-glance sense coverage of testing scripts. But this assumes
we have considered everything that might require testing. Whilst this is
informative, it's not comprehensive. A 100\% in all functions in
\texttt{covr::}, we do not consider done.

An excellent way to arrive at \emph{done} for an algorithm is to define,
even if only broadly, what \emph{done} looks like \emph{before} we set
out. We define what \texttt{code::proof} is requrired.

\hypertarget{code-with-intent}{%
\section{Code with intent}\label{code-with-intent}}

When we think of an algorithm, it's easy to feel overwhelmed by the
complexity. Here are the relationships between inputs, and just some of
the estimators, and outputs in \texttt{varameta}, presented as a
randomised \emph{graph}, a visual representation of a set of nodes,
\(V\), and the edges, \(V \times V\), between them.

\begin{figure}

{\centering \includegraphics{when-is-done-done_files/figure-latex/codebrain-1} 

}

\caption{code::brain before coderegistration.}\label{fig:codebrain}
\end{figure}

The Center for Open Science recommend \emph{preregistering} an
experiment, stating what the hypothesis is and how the analyst intends
to assess the hypothesis as one safeguard against inadvertent
questionable research practices. Analogously, we might think of
preregistering our code as providing some \texttt{code::proof} of the
implementation of our algorithm. In this manuscript, we will think of
\emph{coderegistration}, stating what the intention of an algorithm is,
as - todo: complete

To coderegister an algorithm:

\hypertarget{coderegistration}{%
\subsection{\texorpdfstring{\texttt{code::registration}}{code::registration}}\label{coderegistration}}

In an issue on GitHub:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Describe the algorithm's intended purpose.
\item
  Describe the input parameters and how they will be tested.
\item
  Describe the output parameters and how they will be tested.
\end{enumerate}

Update the coderegistration as needed.

\hypertarget{for-complex-projects}{%
\subsection{For complex projects}\label{for-complex-projects}}

\hypertarget{on-a-piece-of-paper.}{%
\subsubsection{On a piece of paper.}\label{on-a-piece-of-paper.}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a diagram of the inputs and outputs of the algorithm.
\item
  Draw where this algorithm fits in the pipeline of the package, if
  appropriate.
\end{enumerate}

\hypertarget{write-issue}{%
\subsubsection{Write issue}\label{write-issue}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Describe the algorithm's intended purpose.
\item
  Describe the input parameters and how they will be tested.
\item
  Describe the output parameters and how they will be tested.
\end{enumerate}

\hypertarget{sketch-diagram}{%
\subsubsection{Sketch-diagram}\label{sketch-diagram}}

An image or diagram is very help, if not burdonsomely time consuming
(but it often is).

For those comfortable with \emph{graphs} understood as mathematical
objects as a set of vertices from \(V\), and a set of edges
\(V \times V\). There are visualisation options where the vertices can
be tagged with attributes. The code for constructing the following
\texttt{nodes} and \texttt{edges} dataframes has been omitted for
brevity, but all code can be found in this manuscript's associated
repository \href{https://github.com/softloud/neet}{\texttt{neet}} on
GitHub.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(ggraph)}
\KeywordTok{library}\NormalTok{(tidygraph)}
\end{Highlighting}
\end{Shaded}

By tagging the nodes in this graph with the attribute \texttt{state} in
the algorithm: starting with \texttt{input} for the estimators, sample
quartiles (which we denote \(a, q1, m, q3, b\), in order from smallest
to largest); \texttt{estimator}, a collection of functions that provide
statistical methods for preparing summary medians for meta-analysis; and
the \texttt{output} of the estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nodes}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 2
##    node    state    
##    <chr>   <fct>    
##  1 a       input    
##  2 b       input    
##  3 q1      input    
##  4 q3      input    
##  5 m       input    
##  6 n       input    
##  7 hozo    estimator
##  8 pren_c3 estimator
##  9 pren_c1 estimator
## 10 bland   estimator
## # ... with 14 more rows
\end{verbatim}

Edges are specified by a two-column dataframe, \texttt{edges}, where
each row contains a \texttt{to} and \texttt{from} vertex identifier, the
row number of the \texttt{nodes} dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edges}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 84 x 2
##     from    to
##    <dbl> <dbl>
##  1     5     7
##  2     6     7
##  3     1     7
##  4     2     7
##  5     7    15
##  6     7    16
##  7     5    11
##  8     6    11
##  9     1    11
## 10     2    11
## # ... with 74 more rows
\end{verbatim}

These two dataframes cone be converted into a graph object that is
compatible with the \texttt{igraph::} package and \texttt{tidyverse::}
syntax.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph <{-}}\StringTok{ }\KeywordTok{tbl\_graph}\NormalTok{(nodes, edges)}
\end{Highlighting}
\end{Shaded}

These can be

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OperatorTok{\%>\%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{state =} \KeywordTok{fct\_relevel}\NormalTok{(state, }\StringTok{"output"}\NormalTok{)) }\OperatorTok{\%>\%}\StringTok{ }
\StringTok{  }\KeywordTok{ggraph}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_edge\_link}\NormalTok{(}\DataTypeTok{arrow =} \KeywordTok{arrow}\NormalTok{(), }\DataTypeTok{colour =} \StringTok{"lightgrey"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_node\_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ node, }\DataTypeTok{colour =}\NormalTok{ state),  }
                  \DataTypeTok{size =} \DecValTok{5}\NormalTok{,}
                  \DataTypeTok{fill =} \StringTok{"lightgrey"}\NormalTok{,}
                  \DataTypeTok{alpha =} \FloatTok{0.6}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme\_graph}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\NormalTok{hrbrthemes}\OperatorTok{::}\KeywordTok{scale\_color\_ipsum}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale\_y\_reverse}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{coord\_flip}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{when-is-done-done_files/figure-latex/unnamed-chunk-4-1} 

}

\caption{Codebrain after coderegistration.}\label{fig:unnamed-chunk-4}
\end{figure}

\hypertarget{test-driven-workflow}{%
\section{Test-driven workflow}\label{test-driven-workflow}}

\begin{center}\includegraphics{when-is-done-done_files/figure-latex/unnamed-chunk-5-1} \end{center}

This section describes the test-driven workflow presented above as a
\texttt{code::proof}ed coding to doneness.

The model workflow includes three stages, repeated three times, before
returning to the start, the \texttt{code::registration}.

Each phase consists of:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{code::registration}
\item
  tests
\item
  code
\end{enumerate}

\hypertarget{codeproof-workflow-for-coding-to-doneness}{%
\subsection{\texorpdfstring{\texttt{code::proof} workflow for coding to
doneness}{code::proof workflow for coding to doneness}}\label{codeproof-workflow-for-coding-to-doneness}}

The tests vary each time in complexity, so that the complete model cycle
consists of ten phases of work:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{code::registration}
\item
  neet tests, one per function
\item
  code
\item
  \texttt{code::registration}
\item
  neet tests, for all inputs for each function
\item
  code
\item
  \texttt{code::registration}
\item
  tests, and the rest, i.e., any other cases to test for
\item
  code
\item
  \texttt{code::registration}
\end{enumerate}

We use \emph{model} cycle to denote the workflow may be adapted for
different use-cases. Our next section steps through each phase of work.

\hypertarget{coding-to-doneness-toolchain-walkthrough}{%
\section{Coding to doneness toolchain
walkthrough}\label{coding-to-doneness-toolchain-walkthrough}}

\hypertarget{one-neet-test-per-function}{%
\subsection{\texorpdfstring{one \texttt{neet} test per
function}{one neet test per function}}\label{one-neet-test-per-function}}

\hypertarget{coderegistration-1}{%
\subsubsection{Coderegistration}\label{coderegistration-1}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{workflow}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{when-is-done-done_files/figure-latex/unnamed-chunk-6-1} \end{center}

\hypertarget{at-least-one-neet-test-per-function}{%
\subsubsection{\texorpdfstring{At least one \texttt{neet} test per
function}{At least one neet test per function}}\label{at-least-one-neet-test-per-function}}

\begin{itemize}
\tightlist
\item
  introducing the \texttt{neet\ package}
\end{itemize}

\hypertarget{coding-to-doneness-1}{%
\subsubsection{Coding to doneness}\label{coding-to-doneness-1}}

\hypertarget{neet-tests-for-all-inputs}{%
\subsection{\texorpdfstring{\texttt{neet} tests for all
inputs}{neet tests for all inputs}}\label{neet-tests-for-all-inputs}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# todo: diagram}
\end{Highlighting}
\end{Shaded}

Once we have established there is one \texttt{neet} test per function,
we might now perform \texttt{neet} tests for each possibility for
inputs.

\hypertarget{coderegistration-2}{%
\subsubsection{Coderegistration}\label{coderegistration-2}}

\hypertarget{neet-tests-for-all-inputs-1}{%
\subsubsection{\texorpdfstring{\texttt{neet} tests for all
inputs}{neet tests for all inputs}}\label{neet-tests-for-all-inputs-1}}

\hypertarget{coding-to-doneness-2}{%
\subsubsection{Coding to doneness}\label{coding-to-doneness-2}}

\hypertarget{testing-for-doneness}{%
\subsection{Testing for doneness}\label{testing-for-doneness}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# todo: diagram}
\end{Highlighting}
\end{Shaded}

\hypertarget{coderegistration-3}{%
\subsubsection{Coderegistration}\label{coderegistration-3}}

\hypertarget{all-tests-required-for-purpose}{%
\subsubsection{All tests required for
purpose}\label{all-tests-required-for-purpose}}

\hypertarget{coding-to-doneness-3}{%
\subsubsection{Coding to doneness}\label{coding-to-doneness-3}}

\hypertarget{sufficient-codeproof-of-software-for-doneness}{%
\section{\texorpdfstring{Sufficient \texttt{code::proof} of software for
doneness}{Sufficient code::proof of software for doneness}}\label{sufficient-codeproof-of-software-for-doneness}}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-Bryan2017ExcuseMD}{}%
Bryan, Jennifer. 2017. ``Excuse Me, Do You Have a Moment to Talk About
Version Control?'' \emph{PeerJ PrePrints} 5: e3159.

\leavevmode\hypertarget{ref-chang_fundamentalspianopractice_2009a}{}%
Chang, Chuan C. 2009. \emph{Fundamentals of Piano Practice}.

\leavevmode\hypertarget{ref-fraser_questionable_2018}{}%
Fraser, Hannah, Tim Parker, Shinichi Nakagawa, Ashley Barnett, and Fiona
Fidler. 2018. ``Questionable Research Practices in Ecology and
Evolution.'' \emph{PLOS ONE} 13 (7): e0200303.
\url{https://doi.org/10.1371/journal.pone.0200303}.

\leavevmode\hypertarget{ref-galway_flute_1990}{}%
Galway, James. 1990. \emph{Flute}. Kahn \& Averill.

\leavevmode\hypertarget{ref-grayCodeProofPrepare2019}{}%
Gray, Charles T. 2019. ``Code::Proof: Prepare for Most Weather
Conditions.'' In \emph{Statistics and Data Science}, edited by Hien
Nguyen, 22--41. Communications in Computer and Information Science.
Singapore: Springer. \url{https://doi.org/10.1007/978-981-15-1960-4_2}.

\leavevmode\hypertarget{ref-hayes_testing_2019}{}%
Hayes, Alex. 2019. ``Testing Statistical Software - Aleatoric.'' Blog.

\leavevmode\hypertarget{ref-hester_covr_2016}{}%
Hester, Jim. 2016. ``Covr: Bringing Test Coverage to R.''

\leavevmode\hypertarget{ref-karp_robodebtfederalcourt_2019}{}%
Karp, Paul. 2019. ``Robodebt: The Federal Court Ruling and What It Means
for Targeted Welfare Recipients.'' \emph{The Guardian}, November.

\leavevmode\hypertarget{ref-marwick_packaging_2018}{}%
Marwick, Ben, Carl Boettiger, and Lincoln Mullen. 2018. ``Packaging Data
Analytical Work Reproducibly Using R (and Friends).'' e3192v2. PeerJ
Inc. \url{https://doi.org/10.7287/peerj.preprints.3192v2}.

\leavevmode\hypertarget{ref-mcilroy201720}{}%
McIlroy, T. 2017. ``20,000 People Sent Centrelink `Robo-Debt' Notices
Found to Owe Less or Nothing.'' \emph{Canberra Times} 13.

\leavevmode\hypertarget{ref-riederer_rmarkdowndrivendevelopment_2019}{}%
Riederer, Emily. 2019. ``RMarkdown Driven Development (RmdDD).''
\emph{Emily Riederer}.

\leavevmode\hypertarget{ref-_rstudiocloud_}{}%
``RStudio Cloud.'' n.d. https://rstudio.cloud/learn/primers.

\leavevmode\hypertarget{ref-wickham_r_2015}{}%
Wickham, H. 2015. \emph{R Packages: Organize, Test, Document, and Share
Your Code}. O'Reilly Media.

\leavevmode\hypertarget{ref-wilson_best_2014}{}%
Wilson, Greg, D. A. Aruliah, C. Titus Brown, Neil P. Chue Hong, Matt
Davis, Richard T. Guy, Steven H. D. Haddock, et al. 2014. ``Best
Practices for Scientific Computing.'' Edited by Jonathan A. Eisen.
\emph{PLoS Biology} 12 (1): e1001745.
\url{https://doi.org/10.1371/journal.pbio.1001745}.

\leavevmode\hypertarget{ref-wilson_good_2017}{}%
Wilson, Greg, Jennifer Bryan, Karen Cranston, Justin Kitzes, Lex
Nederbragt, and Tracy K. Teal. 2017. ``Good Enough Practices in
Scientific Computing.'' Edited by Francis Ouellette. \emph{PLOS
Computational Biology} 13 (6): e1005510.
\url{https://doi.org/10.1371/journal.pcbi.1005510}.

\leavevmode\hypertarget{ref-yuan_simpletestingcan_2014}{}%
Yuan, Ding, Yu Luo, Xin Zhuang, Guilherme Renna Rodrigues, Xu Zhao,
Yongle Zhang, Pranay U. Jain, and Michael Stumm. 2014. ``Simple Testing
Can Prevent Most Critical Failures: An Analysis of Production Failures
in Distributed Data-Intensive Systems.'' In \emph{Proceedings of the
11th USENIX Conference on Operating Systems Design and Implementation},
249--65. OSDI'14. Broomfield, CO: USENIX Association.
\end{cslreferences}

\end{document}
